{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81271261-5cbe-47a6-84c1-6fcdd1cb3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061a7da7-9303-4019-a9cb-7a1e0d995fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc7e998-61ce-497b-89f4-bcf4616758b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    f = open(\"dinosaur_island.txt\", \"r\")\n",
    "    file_data = f.read()\n",
    "    return file_data\n",
    "\n",
    "def preprocess_data(file_data):\n",
    "    names = file_data.strip().lower().split('\\n')\n",
    "    name_num = len(names)\n",
    "    max_len = max([len(name) for name in names])\n",
    "    charset = 29 # 26=end-of-sequence, 27=beginning-of-sequence, 28=padding\n",
    "    x_train = np.zeros((name_num, max_len, charset))\n",
    "    y_train = np.zeros((name_num, max_len, charset))\n",
    "    a_int = ord('a')\n",
    "    for n in range(name_num):\n",
    "        capitals = sum(1 for ch in names[n] if ch.isupper())\n",
    "        if capitals > 1:\n",
    "            print(i + 1)\n",
    "        for i in range(max_len):\n",
    "            if i == 0:\n",
    "                x_train[n, i, 27] = 1\n",
    "            else:\n",
    "                x_train[n, i] = y_train[n, i - 1]\n",
    "            if i < len(names[n]):\n",
    "                y_train[n, i, ord(names[n][i]) - a_int] = 1\n",
    "            elif i == len(names[n]):\n",
    "                y_train[n, i, 26] = 1\n",
    "            else:\n",
    "                y_train[n, i, 28] = 1\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c19d9b-8ca6-4311-bbc6-999817ecf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNSeqSoftmax:\n",
    "    def __init__(self, input_dim, seq_len, output_dim, hidden_size=128, unroll=5):\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_size= hidden_size\n",
    "        self.unroll = unroll\n",
    "        weight_range1 = np.sqrt(3)/np.sqrt((input_dim + hidden_size)/2)\n",
    "        self.xh = np.array(rng.uniform(-weight_range1, weight_range1, size=(input_dim, hidden_size)))\n",
    "        self.hh = np.array(rng.uniform(-weight_range1, weight_range1, size=(hidden_size, hidden_size)))\n",
    "        self.bias2 = np.array(rng.uniform(-weight_range1, weight_range1, size=(1, hidden_size)))\n",
    "        weight_range2 = np.sqrt(3)/np.sqrt((hidden_size + output_dim)/2)\n",
    "        self.hq = np.array(rng.uniform(-weight_range2, weight_range2, size=(hidden_size, output_dim)))\n",
    "        self.bias3 = np.array(rng.uniform(-weight_range2, weight_range2, size=(1, output_dim)))\n",
    "        self.h = 0\n",
    "        self.dj_dwxh = 0\n",
    "        self.dj_dwhh = 0\n",
    "        self.dj_db2 = 0\n",
    "        self.dj_dwhq = 0\n",
    "        self.dj_db3 = 0\n",
    "        self.eta = 0.01\n",
    "\n",
    "    def softmax(self, x):\n",
    "        shifted_x = x - np.max(x, axis=-1, keepdims=True)\n",
    "        exp_x = np.exp(shifted_x)\n",
    "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.input = x\n",
    "        self.output1 = np.dot(x, self.xh)\n",
    "        self.output2 = np.zeros((self.batch_size, self.seq_len, self.hidden_size))\n",
    "        for i in range(self.seq_len):\n",
    "            if i == 0:\n",
    "                self.output2[:, i] = np.tanh(self.output1[:, i, :] + self.bias2)\n",
    "            else:\n",
    "                self.output2[:, i] = np.tanh(self.output1[:, i, :] + np.dot(self.output2[:, i - 1], self.hh) + self.bias2)\n",
    "        self.output3 = self.softmax(np.dot(self.output2, self.hq) + self.bias3)\n",
    "        return self.output3\n",
    "\n",
    "    def backward(self, y):\n",
    "        error3 = (self.output3 - y)\n",
    "        error2 = np.zeros((self.batch_size, self.seq_len, self.hidden_size))\n",
    "        self.dj_dwhq = np.zeros((self.batch_size, self.hidden_size, self.output_dim))\n",
    "        for i in range(self.batch_size):\n",
    "            error2[i] = np.dot(error3[i], self.hq.T)\n",
    "            self.dj_dwhq[i] = np.dot(self.output2[i].T, error3[i])\n",
    "        self.dj_dwhq = np.mean(self.dj_dwhq, axis=0)\n",
    "        self.dj_b3 = np.mean(np.sum(error3, axis=0), axis=0, keepdims=True)\n",
    "        \n",
    "        self.hq -= np.clip(self.dj_dwhq, a_min=-1, a_max=1) * self.eta\n",
    "        self.bias3 -= np.clip(self.dj_db3, a_min=-1, a_max=1) * self.eta\n",
    "\n",
    "        self.dj_dwhh = 0\n",
    "        self.dj_dwxh = 0\n",
    "        self.dj_db2 = 0\n",
    "        for n in reversed(range(self.seq_len)):\n",
    "            cc = error2[:, n]\n",
    "            dj_db2_n = np.zeros_like(self.bias2)\n",
    "            dj_dwxh_n = np.zeros_like(self.xh)\n",
    "            dj_dwhh_n = np.zeros_like(self.hh)\n",
    "            for i in reversed(range(max(0, n - self.unroll + 1), n + 1)):\n",
    "                cc *= 1 - (self.output2[:, i]) ** 2\n",
    "                if i > 0:\n",
    "                    dj_dwhh_n += np.dot(self.output2[:, i - 1].T, cc)\n",
    "                    dj_db2_n += np.sum(cc, axis=0, keepdims=True)\n",
    "                dj_dwxh_n += np.dot(self.input[:, i].T, cc)\n",
    "                cc = np.dot(cc, self.hh)\n",
    "            self.dj_dwhh += dj_dwhh_n\n",
    "            self.dj_dwxh += dj_dwxh_n\n",
    "            self.dj_db2 += dj_db2_n\n",
    "\n",
    "        self.hh -= np.clip(self.dj_dwhh, a_min=-1, a_max=1) * self.eta\n",
    "        self.xh -= np.clip(self.dj_dwxh, a_min=-1, a_max=1) * self.eta\n",
    "        self.bias2 -= np.clip(self.dj_db2, a_min=-1, a_max=1) * self.eta\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        yhat = self.forward(X)\n",
    "        total_loss = 0\n",
    "        for b in range(yhat.shape[0]):\n",
    "            for i in range(yhat.shape[1]):\n",
    "                total_loss += -np.dot(np.log(np.clip(yhat[b, i], 10e-10, 1)), y[b, i])\n",
    "        loss = total_loss / (yhat.shape[0] * yhat.shape[1])\n",
    "        return loss\n",
    "\n",
    "    def prepare_minibatches(self, X, y, size=32, shuffle=True):\n",
    "        if shuffle:\n",
    "            idx = np.arange(0, X.shape[0])\n",
    "            idx = np.random.permutation(idx)\n",
    "            X = X[idx, :]\n",
    "            y = y[idx]\n",
    "\n",
    "        batch_num = np.ceil(X.shape[0] / size)\n",
    "        \n",
    "        X_batches = np.array_split(X, batch_num)\n",
    "        y_batches = np.array_split(y, batch_num)\n",
    "\n",
    "        return (X_batches, y_batches)\n",
    "\n",
    "    def fit(self, X, y, epochs=3, eta=0.01, batch_size=32, val_X=None, val_y=None):\n",
    "        self.eta = eta\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for i in range(epochs):\n",
    "            self.eta = max(eta * (0.8 ** np.floor(i / 10)), 0.0001) # learning rate decay\n",
    "            X_batches, y_batches = self.prepare_minibatches(X, y, batch_size)\n",
    "            for X_sample, y_sample in zip(X_batches, y_batches):\n",
    "                result = self.forward(X_sample)\n",
    "                self.backward(y_sample)\n",
    "            train_losses.append(self.loss(X, y))\n",
    "            if val_X is not None and val_y is not None:\n",
    "                val_losses.append(self.loss(val_X, val_y))\n",
    "                print(\"Epoch \", i + 1, \", Loss: \", train_losses[-1], \" Val loss: \", val_losses[-1])\n",
    "            else:\n",
    "                print(\"Epoch \", i + 1, \", Loss: \", train_losses[-1])\n",
    "        if val_X is not None and val_y is not None:\n",
    "            return (train_losses, val_losses)\n",
    "        return train_losses\n",
    "        \n",
    "    def predict(self, x):\n",
    "        probs = self.forward(x)\n",
    "        batch = x.shape[0]\n",
    "        a_ind = ord('a')\n",
    "        probs_max = np.argmax(probs, axis=-1)\n",
    "        prediction = []\n",
    "        for b in range(batch):\n",
    "            word = ''\n",
    "            for i in range(self.seq_len):\n",
    "                char_ind = probs_max[b, i]\n",
    "                if char_ind < 26:\n",
    "                    word += chr(a_ind + char_ind)\n",
    "                elif char_ind == 26:\n",
    "                    word += '$'\n",
    "                elif char_ind == 27:\n",
    "                    word += '*'\n",
    "                else:\n",
    "                    word += '#'\n",
    "            prediction.append(word)\n",
    "        return prediction\n",
    "\n",
    "    def predictfrom(self, prefix):\n",
    "        prefix = prefix.lower()\n",
    "        charset = 29\n",
    "        chars = [np.zeros(charset)]\n",
    "        chars[0][27] = 1\n",
    "        a_int = ord('a')\n",
    "        for ch in prefix:\n",
    "            ch_onehot = np.zeros(charset)\n",
    "            ch_onehot[ord(ch) - a_int] = 1\n",
    "            chars.append(ch_onehot)\n",
    "        result = prefix\n",
    "        lasthidden = np.zeros(self.hidden_size)\n",
    "        for ch_onehot in chars:\n",
    "            lasthidden = np.tanh(np.dot(ch_onehot, self.xh) + np.dot(lasthidden, self.hh) + self.bias2)\n",
    "        while len(result) < 25:\n",
    "            rnn_output = np.dot(lasthidden, self.hq) + self.bias3\n",
    "            ind = np.argmax(rnn_output)\n",
    "            if ind < 26:\n",
    "                letter = chr(ind + a_int)\n",
    "                result += letter\n",
    "                ch_onehot = np.zeros(charset)\n",
    "                ch_onehot[ind] = 1\n",
    "                lasthidden = np.tanh(np.dot(ch_onehot, self.xh) + np.dot(lasthidden, self.hh) + self.bias2)\n",
    "            else:\n",
    "                break\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943160e7-8223-49ea-a9df-5c2af0fe4876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (1539, 23, 29)\n",
      "y_train shape:  (1539, 23, 29)\n"
     ]
    }
   ],
   "source": [
    "file_data = read_data()\n",
    "x_train, y_train = preprocess_data(file_data)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ea4cb45-892d-42ab-81dc-f0fd65f70b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , Loss:  1.3779697324317024\n",
      "Epoch  2 , Loss:  1.1721163409652904\n",
      "Epoch  3 , Loss:  1.1792427927538964\n",
      "Epoch  4 , Loss:  1.092028319340979\n",
      "Epoch  5 , Loss:  1.0991688261987205\n",
      "Epoch  6 , Loss:  1.0554846175174728\n",
      "Epoch  7 , Loss:  1.0379949859072573\n",
      "Epoch  8 , Loss:  1.0507885856819048\n",
      "Epoch  9 , Loss:  1.021701649419817\n",
      "Epoch  10 , Loss:  1.025670865174154\n",
      "Epoch  11 , Loss:  1.0042827183577423\n",
      "Epoch  12 , Loss:  1.0153390683822157\n",
      "Epoch  13 , Loss:  0.9910034100789201\n",
      "Epoch  14 , Loss:  0.9948117818544917\n",
      "Epoch  15 , Loss:  0.9839719593022547\n",
      "Epoch  16 , Loss:  0.9773922972023048\n",
      "Epoch  17 , Loss:  0.974889902100372\n",
      "Epoch  18 , Loss:  0.9686588835207638\n",
      "Epoch  19 , Loss:  0.9656710769367863\n",
      "Epoch  20 , Loss:  0.9791834490813749\n",
      "Epoch  21 , Loss:  0.9569731794988008\n",
      "Epoch  22 , Loss:  0.9618548670385122\n",
      "Epoch  23 , Loss:  0.9440939872533143\n",
      "Epoch  24 , Loss:  0.953867740211214\n",
      "Epoch  25 , Loss:  0.9430630881498937\n",
      "Epoch  26 , Loss:  0.9633943328508405\n",
      "Epoch  27 , Loss:  0.9412191247610432\n",
      "Epoch  28 , Loss:  0.9369254203781324\n",
      "Epoch  29 , Loss:  0.9345450989692388\n",
      "Epoch  30 , Loss:  0.9342482055268766\n",
      "Epoch  31 , Loss:  0.9264095818682863\n",
      "Epoch  32 , Loss:  0.924483111264637\n",
      "Epoch  33 , Loss:  0.9235146494066974\n",
      "Epoch  34 , Loss:  0.9237712334500758\n",
      "Epoch  35 , Loss:  0.9213541551598412\n",
      "Epoch  36 , Loss:  0.920364685528125\n",
      "Epoch  37 , Loss:  0.9219703795549793\n",
      "Epoch  38 , Loss:  0.917464824410464\n",
      "Epoch  39 , Loss:  0.9144869424424618\n",
      "Epoch  40 , Loss:  0.9104467999275145\n",
      "Epoch  41 , Loss:  0.907414166954957\n",
      "Epoch  42 , Loss:  0.9072987872090958\n",
      "Epoch  43 , Loss:  0.9041090344898011\n",
      "Epoch  44 , Loss:  0.9070236702855926\n",
      "Epoch  45 , Loss:  0.9041393896501233\n",
      "Epoch  46 , Loss:  0.9074401218934006\n",
      "Epoch  47 , Loss:  0.9051998029043289\n",
      "Epoch  48 , Loss:  0.8986554176870502\n",
      "Epoch  49 , Loss:  0.8988652203800573\n",
      "Epoch  50 , Loss:  0.8994904322239257\n"
     ]
    }
   ],
   "source": [
    "model = RNNSeqSoftmax(input_dim=29, seq_len=23, output_dim=29, hidden_size=64, unroll=5)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, eta=0.01, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d49094-e2ac-42a6-92cc-e73de1b999af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anchanosaurus$#########']\n",
      "['aaahroonatas$##########']\n",
      "['ainoneasachus$#########']\n",
      "['aanoaaasaurus$#########']\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(x_train[0].reshape(1, 23, 29))\n",
    "print(out)\n",
    "out = model.predict(x_train[200].reshape(1, 23, 29))\n",
    "print(out)\n",
    "out = model.predict(x_train[400].reshape(1, 23, 29))\n",
    "print(out)\n",
    "out = model.predict(x_train[600].reshape(1, 23, 29))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f4272d9-82a3-4b96-8203-f4463defe700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angosaurus\n",
      "tyranosaurus\n",
      "velosaurus\n",
      "pterosaurus\n",
      "sterosaurus\n"
     ]
    }
   ],
   "source": [
    "word = model.predictfrom('')\n",
    "print(word)\n",
    "word = model.predictfrom('tyran')\n",
    "print(word)\n",
    "word = model.predictfrom('velo')\n",
    "print(word)\n",
    "word = model.predictfrom('pte')\n",
    "print(word)\n",
    "word = model.predictfrom('st')\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf78ccfd-1c7b-4dbb-a864-dcd013ef4733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stegostegostegostegostegostego\n"
     ]
    }
   ],
   "source": [
    "word = model.predictfrom('stegostegostegostegostegostego')\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3ccbb-8d57-4788-bc28-065d1e081c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
